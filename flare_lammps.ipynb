{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28FayYtEbldl"
      },
      "source": [
        "# FLARE - LAMMPS tutorial\n",
        "\n",
        "Yu Xie (xiey@g.harvard.edu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7evLlw5Juek"
      },
      "source": [
        "## What will you learn in this tutorial\n",
        "\n",
        "In the [FLARE tutorial](https://colab.research.google.com/drive/1rZ-p3kN5CJbPJgD8HuQHSc7ecmwZYse6), we learned how to run on-the-fly training with FLARE and MD engine from ASE. In this tutorial, you will learn how to\n",
        "\n",
        "- Deploy the trained FLARE Bayesian force field to large-scale MD in LAMMPS ðŸ‘‰ [run LAMMPS MD with FLARE pair style and uncertainty](#scrollTo=Run_MD_in_LAMMPS_with_uncertainty)\n",
        "\n",
        "- Use a faster and more flexible MD for the on-the-fly training ðŸ‘‰ [train FLARE force field on-the-fly with LAMMPS MD](#scrollTo=Bayesian_active_learning_with_FLARE_and_LAMMPS_MD)\n",
        "\n",
        "> Why do we use LAMMPS MD for on-the-fly training?\n",
        ">\n",
        "> 1. ASE only provides very limited MD engines (Verlet, Langevin, NPT, etc.) and functionalities.\n",
        ">\n",
        "> 2. The energy/forces/stress are predicted by sparse GP force field, whose computational cost grows with increasing training set size, and can be slow as the training proceeds.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BiQT21KTTts"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kqr_3g9KSR9"
      },
      "source": [
        "## Install FLARE\n",
        "\n",
        "The installation will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp_K0aFVJ60Q",
        "outputId": "64c032df-19d0-47a5-de78-eff2ef11093f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping mkl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping mkl-devel as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping mkl-include as it is not installed.\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libmkl-intel-thread' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-gf-lp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-blacs-intelmpi-lp64' for glob '*mkl*'\n",
            "Note, selecting 'intel-mkl-linktool' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-scalapack-lp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-gf-ilp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-gnu-thread' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-avx2' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-full-dev' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-mc' for glob '*mkl*'\n",
            "Note, selecting 'intel-mkl-cluster' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-mc' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-rt' for glob '*mkl*'\n",
            "Note, selecting 'libmkldnn-dev' for glob '*mkl*'\n",
            "Note, selecting 'php-srmklive-flysystem-dropbox-v2' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-pgi-thread' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-cluster-dev' for glob '*mkl*'\n",
            "Note, selecting 'revolution-mkl' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-threading-dev' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-avx' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-meta-computational' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-def' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-dev' for glob '*mkl*'\n",
            "Note, selecting 'mklibs-copy' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-avx2' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-mc3' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-locale' for glob '*mkl*'\n",
            "Note, selecting 'libpam-mklocaluser' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-cdft-core' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-intel-lp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-avx' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-def' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-avx512-mic' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-intel-ilp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-blacs-openmpi-lp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-tbb-thread' for glob '*mkl*'\n",
            "Note, selecting 'libmkldnn1' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-core' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-mc2' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-mc3' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-sequential' for glob '*mkl*'\n",
            "Note, selecting 'intel-mkl-doc' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-computational-dev' for glob '*mkl*'\n",
            "Note, selecting 'intel-mkl-full' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-interface-dev' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-avx512' for glob '*mkl*'\n",
            "Note, selecting 'ldraw-mklist' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-blacs-sgimpt-lp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-cmpt' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-blacs-openmpi-ilp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-avx512' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-blacs-intelmpi-ilp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-meta-cluster' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-meta-interface' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-meta-threading' for glob '*mkl*'\n",
            "Note, selecting 'mklibs' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-scalapack-ilp64' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-blacs-sgimpt-ilp64' for glob '*mkl*'\n",
            "Note, selecting 'intel-mkl' for glob '*mkl*'\n",
            "Note, selecting 'libmkl-vml-avx512-mic' for glob '*mkl*'\n",
            "Package 'libmkldnn-dev' is not installed, so not removed\n",
            "Package 'libmkldnn1' is not installed, so not removed\n",
            "Package 'php-srmklive-flysystem-dropbox-v2' is not installed, so not removed\n",
            "Package 'intel-mkl-linktool' is not installed, so not removed\n",
            "Package 'libpam-mklocaluser' is not installed, so not removed\n",
            "Package 'mklibs' is not installed, so not removed\n",
            "Package 'mklibs-copy' is not installed, so not removed\n",
            "Package 'intel-mkl' is not installed, so not removed\n",
            "Package 'intel-mkl-cluster' is not installed, so not removed\n",
            "Package 'intel-mkl-doc' is not installed, so not removed\n",
            "Package 'intel-mkl-full' is not installed, so not removed\n",
            "Package 'ldraw-mklist' is not installed, so not removed\n",
            "Package 'libmkl-avx' is not installed, so not removed\n",
            "Package 'libmkl-avx2' is not installed, so not removed\n",
            "Package 'libmkl-avx512' is not installed, so not removed\n",
            "Package 'libmkl-avx512-mic' is not installed, so not removed\n",
            "Package 'libmkl-blacs-intelmpi-ilp64' is not installed, so not removed\n",
            "Package 'libmkl-blacs-intelmpi-lp64' is not installed, so not removed\n",
            "Package 'libmkl-blacs-openmpi-ilp64' is not installed, so not removed\n",
            "Package 'libmkl-blacs-openmpi-lp64' is not installed, so not removed\n",
            "Package 'libmkl-blacs-sgimpt-ilp64' is not installed, so not removed\n",
            "Package 'libmkl-blacs-sgimpt-lp64' is not installed, so not removed\n",
            "Package 'libmkl-cdft-core' is not installed, so not removed\n",
            "Package 'libmkl-cluster-dev' is not installed, so not removed\n",
            "Package 'libmkl-computational-dev' is not installed, so not removed\n",
            "Package 'libmkl-core' is not installed, so not removed\n",
            "Package 'libmkl-def' is not installed, so not removed\n",
            "Package 'libmkl-dev' is not installed, so not removed\n",
            "Package 'libmkl-full-dev' is not installed, so not removed\n",
            "Package 'libmkl-gf-ilp64' is not installed, so not removed\n",
            "Package 'libmkl-gf-lp64' is not installed, so not removed\n",
            "Package 'libmkl-gnu-thread' is not installed, so not removed\n",
            "Package 'libmkl-intel-ilp64' is not installed, so not removed\n",
            "Package 'libmkl-intel-lp64' is not installed, so not removed\n",
            "Package 'libmkl-intel-thread' is not installed, so not removed\n",
            "Package 'libmkl-interface-dev' is not installed, so not removed\n",
            "Package 'libmkl-locale' is not installed, so not removed\n",
            "Package 'libmkl-mc' is not installed, so not removed\n",
            "Package 'libmkl-mc3' is not installed, so not removed\n",
            "Package 'libmkl-meta-cluster' is not installed, so not removed\n",
            "Package 'libmkl-meta-computational' is not installed, so not removed\n",
            "Package 'libmkl-meta-interface' is not installed, so not removed\n",
            "Package 'libmkl-meta-threading' is not installed, so not removed\n",
            "Package 'libmkl-pgi-thread' is not installed, so not removed\n",
            "Package 'libmkl-rt' is not installed, so not removed\n",
            "Package 'libmkl-scalapack-ilp64' is not installed, so not removed\n",
            "Package 'libmkl-scalapack-lp64' is not installed, so not removed\n",
            "Package 'libmkl-sequential' is not installed, so not removed\n",
            "Package 'libmkl-tbb-thread' is not installed, so not removed\n",
            "Package 'libmkl-threading-dev' is not installed, so not removed\n",
            "Package 'libmkl-vml-avx' is not installed, so not removed\n",
            "Package 'libmkl-vml-avx2' is not installed, so not removed\n",
            "Package 'libmkl-vml-avx512' is not installed, so not removed\n",
            "Package 'libmkl-vml-avx512-mic' is not installed, so not removed\n",
            "Package 'libmkl-vml-cmpt' is not installed, so not removed\n",
            "Package 'libmkl-vml-def' is not installed, so not removed\n",
            "Package 'libmkl-vml-mc' is not installed, so not removed\n",
            "Package 'libmkl-vml-mc2' is not installed, so not removed\n",
            "Package 'libmkl-vml-mc3' is not installed, so not removed\n",
            "Package 'revolution-mkl' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "liblapacke is already the newest version (3.10.0-2ubuntu1).\n",
            "liblapacke-dev is already the newest version (3.10.0-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "PPA publishes dbgsym, you may need to include 'main/debug' component\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu/ jammy main'\n",
            "Description:\n",
            "Toolchain test builds; see https://wiki.ubuntu.com/ToolChain\n",
            "\n",
            "More info: https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test\n",
            "Adding repository.\n",
            "Found existing deb entry in /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Adding deb entry to /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Found existing deb-src entry in /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/ubuntu-toolchain-r-ubuntu-test.gpg with fingerprint 60C317803A41BA51845E371A1E9377A2BA9EF27F\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "29 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++-9 is already the newest version (9.5.0-1ubuntu1~22.04).\n",
            "gcc-9 is already the newest version (9.5.0-1ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "fatal: destination path 'flare' already exists and is not an empty directory.\n",
            "Processing /content/flare\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<=1.20.3,>=1.18 (from mir-flare==1.1.2)\n",
            "  Using cached numpy-1.20.3.zip (7.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (1.10.1)\n",
            "Collecting memory_profiler (from mir-flare==1.1.2)\n",
            "  Using cached memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (0.56.4)\n",
            "Collecting ase (from mir-flare==1.1.2)\n",
            "  Using cached ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (7.34.0)\n",
            "Requirement already satisfied: pytest>=4.6 in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (7.4.0)\n",
            "Collecting pytest-mock (from mir-flare==1.1.2)\n",
            "  Using cached pytest_mock-3.11.1-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cmake>=3.14.5 in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (3.27.2)\n",
            "Collecting jupyter (from mir-flare==1.1.2)\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (6.5.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (6.0.1)\n",
            "Collecting docutils==0.17.1 (from mir-flare==1.1.2)\n",
            "  Using cached docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
            "Collecting alabaster==0.7.12 (from mir-flare==1.1.2)\n",
            "  Using cached alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from mir-flare==1.1.2) (2.12.1)\n",
            "Collecting pygments==2.11.2 (from mir-flare==1.1.2)\n",
            "  Using cached Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting nptyping (from mir-flare==1.1.2)\n",
            "  Using cached nptyping-2.5.0-py3-none-any.whl (37 kB)\n",
            "Collecting nbsphinx (from mir-flare==1.1.2)\n",
            "  Using cached nbsphinx-0.9.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->mir-flare==1.1.2) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->mir-flare==1.1.2) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->mir-flare==1.1.2) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->mir-flare==1.1.2) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6->mir-flare==1.1.2) (2.0.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from ase->mir-flare==1.1.2) (3.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython->mir-flare==1.1.2)\n",
            "  Using cached jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->mir-flare==1.1.2) (4.8.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->mir-flare==1.1.2) (6.5.5)\n",
            "Collecting qtconsole (from jupyter->mir-flare==1.1.2)\n",
            "  Using cached qtconsole-5.4.3-py3-none-any.whl (121 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->mir-flare==1.1.2) (6.1.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->mir-flare==1.1.2) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->mir-flare==1.1.2) (7.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler->mir-flare==1.1.2) (5.9.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->mir-flare==1.1.2) (1.2.1)\n",
            "Requirement already satisfied: sphinx>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbsphinx->mir-flare==1.1.2) (5.0.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mir-flare==1.1.2) (0.39.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->mir-flare==1.1.2) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->mir-flare==1.1.2) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->ase->mir-flare==1.1.2) (2.8.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert->mir-flare==1.1.2) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->mir-flare==1.1.2) (2.18.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->mir-flare==1.1.2) (4.19.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->mir-flare==1.1.2) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->mir-flare==1.1.2) (0.2.6)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (1.1.8)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (1.0.6)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (2.2.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->mir-flare==1.1.2) (2.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->mir-flare==1.1.2) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->mir-flare==1.1.2) (0.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->mir-flare==1.1.2) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->mir-flare==1.1.2) (6.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->mir-flare==1.1.2) (3.6.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->mir-flare==1.1.2) (3.0.8)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (1.5.7)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->mir-flare==1.1.2) (1.0.0)\n",
            "Collecting qtpy>=2.0.1 (from qtconsole->jupyter->mir-flare==1.1.2)\n",
            "  Using cached QtPy-2.3.1-py3-none-any.whl (84 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->mir-flare==1.1.2) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->mir-flare==1.1.2) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->mir-flare==1.1.2) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->mir-flare==1.1.2) (0.9.2)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->mir-flare==1.1.2) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->mir-flare==1.1.2) (0.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->mir-flare==1.1.2) (2023.7.22)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->mir-flare==1.1.2) (21.2.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->mir-flare==1.1.2) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->mir-flare==1.1.2) (1.6.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->mir-flare==1.1.2) (1.15.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->mir-flare==1.1.2) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->mir-flare==1.1.2) (2.21)\n",
            "Building wheels for collected packages: mir-flare, numpy\n",
            "  Building wheel for mir-flare (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-flare: filename=mir_flare-1.1.2-cp310-cp310-linux_x86_64.whl size=793168 sha256=8b2710ff6d72e7955bedb15019fb421a085cbb26ddf6f163b24641ed3b03ec36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i41q7dxv/wheels/65/e5/fd/19a021a504bf7d188e5080d89d39c0a656ef27292484b5e8f2\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built mir-flare\n",
            "Failed to build numpy\n",
            "\u001b[31mERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install a working copy of lapack/lapacke.\n",
        "! pip uninstall -y mkl mkl-devel mkl-include\n",
        "! sudo apt remove *mkl*\n",
        "! sudo apt install liblapacke liblapacke-dev\n",
        "\n",
        "# Switch the Colab C++ compiler to g++-9.\n",
        "! sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test\n",
        "! sudo apt update\n",
        "! sudo apt install gcc-9 g++-9\n",
        "! update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 50\n",
        "! update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 50\n",
        "\n",
        "!git clone -b 1.3.3 https://github.com/mir-group/flare.git\n",
        "!cd flare && pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAPg_gJoK_7L"
      },
      "source": [
        "## Install LAMMPS with FLARE pair styles and compute commands\n",
        "\n",
        "The LAMMPS code files for FLARE are in the `flare/lammps_plugins` folder. We go to the folder and run the `install.sh`. Then we go to the `lammps` folder, and run `cmake` and `make` to compile the LAMMPS executable.\n",
        "\n",
        "This will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jHkyETiwJrlV",
        "outputId": "23085fa5-e2d9-4570-a82d-30d1dfc60988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-08-23 09:52:09--  https://github.com/lammps/lammps/archive/refs/tags/patch_17Feb2022.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/lammps/lammps/zip/refs/tags/patch_17Feb2022 [following]\n",
            "--2023-08-23 09:52:09--  https://codeload.github.com/lammps/lammps/zip/refs/tags/patch_17Feb2022\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: â€˜patch_17Feb2022.zipâ€™\n",
            "\n",
            "patch_17Feb2022.zip     [        <=>         ] 124.90M  6.63MB/s    in 20s     \n",
            "\n",
            "2023-08-23 09:52:29 (6.34 MB/s) - â€˜patch_17Feb2022.zipâ€™ saved [130962706]\n",
            "\n",
            "mv: cannot move 'lammps-patch_17Feb2022' to 'lammps/lammps-patch_17Feb2022': Directory not empty\n",
            "ln: failed to create symbolic link '../../lammps/src/KOKKOS/cutoffs_kokkos.h': File exists\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:13 (cmake_policy):\n",
            "  The OLD behavior for policy CMP0109 will be removed from a future version\n",
            "  of CMake.\n",
            "\n",
            "  The cmake-policies(7) manual explains that the OLD behaviors of all\n",
            "  policies are deprecated and that a policy should be set to OLD only under\n",
            "  specific short-term circumstances.  Projects should be ported to the NEW\n",
            "  behavior and not rely on setting a policy to OLD.\n",
            "\n",
            "\u001b[0m\n",
            "-- Appending /usr/local/cuda/lib64/stubs to CMAKE_LIBRARY_PATH: /usr/local/cuda/lib64/stubs\n",
            "-- Running check for auto-generated files from make-based build system\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Eigen3 download requested - we will build our own\n",
            "\u001b[33mCMake Warning (dev) at /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.27/Modules/ExternalProject.cmake:3136 (message):\n",
            "  The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
            "  not set.  The policy's OLD behavior will be used.  When using a URL\n",
            "  download, the timestamps of extracted files should preferably be that of\n",
            "  the time of extraction, otherwise code that depends on the extracted\n",
            "  contents might not be rebuilt if the URL changes.  The OLD behavior\n",
            "  preserves the timestamps from the archive instead, but this is usually not\n",
            "  what you want.  Update your project to the NEW behavior or specify the\n",
            "  DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
            "  robustness issue.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.27/Modules/ExternalProject.cmake:4345 (_ep_add_download_command)\n",
            "  Modules/Packages/MACHDYN.cmake:16 (ExternalProject_Add)\n",
            "  CMakeLists.txt:455 (include)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Generating style headers...\n",
            "-- Generating package headers...\n",
            "-- Generating lmpinstalledpkgs.h...\n",
            "-- Could NOT find ClangFormat (missing: ClangFormat_EXECUTABLE) (Required is at least version \"8.0\")\n",
            "-- The following tools and libraries have been found and configured:\n",
            " * Git\n",
            " * MPI\n",
            " * OpenMP\n",
            " * JPEG\n",
            " * PNG\n",
            " * ZLIB\n",
            "\n",
            "-- <<< Build configuration >>>\n",
            "   Operating System: Linux Ubuntu 22.04\n",
            "   Build type:       RelWithDebInfo\n",
            "   Install path:     /root/.local\n",
            "   Generator:        Unix Makefiles using /usr/bin/gmake\n",
            "-- Enabled packages: MACHDYN;MANYBODY\n",
            "-- <<< Compilers and Flags: >>>\n",
            "-- C++ Compiler:     /usr/bin/c++\n",
            "      Type:          GNU\n",
            "      Version:       9.5.0\n",
            "      C++ Flags:     -O2 -g -DNDEBUG\n",
            "      Defines:       LAMMPS_SMALLBIG;LAMMPS_MEMALIGN=64;LAMMPS_OMP_COMPAT=4;LAMMPS_JPEG;LAMMPS_PNG;LAMMPS_GZIP;LAMMPS_FFMPEG\n",
            "-- <<< Linker flags: >>>\n",
            "-- Executable name:  lmp\n",
            "-- Static library flags:    \n",
            "-- <<< MPI flags >>>\n",
            "-- MPI_defines:      MPICH_SKIP_MPICXX;OMPI_SKIP_MPICXX;_MPICC_H\n",
            "-- MPI includes:     /usr/lib/x86_64-linux-gnu/openmpi/include;/usr/lib/x86_64-linux-gnu/openmpi/include/openmpi\n",
            "-- MPI libraries:    /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so;/usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi.so;\n",
            "-- Configuring done (3.7s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/lammps/build\n",
            "[  1%] Built target bond.h\n",
            "[  1%] Built target force.h\n",
            "[  1%] Built target angle.h\n",
            "[  1%] Built target atom.h\n",
            "[  1%] Built target citeme.h\n",
            "[  2%] Built target Eigen3_build\n",
            "[  3%] Built target comm.h\n",
            "-- Git Directory: /content/lammps/.git\n",
            "-- Generating lmpgitversion.h...\n",
            "[  3%] Built target gitversion\n",
            "[  3%] Built target lmppython.h\n",
            "[  3%] Built target lmptype.h\n",
            "[  3%] Built target memory.h\n",
            "[  3%] Built target modify.h\n",
            "[  3%] Built target neighbor.h\n",
            "[  3%] Built target output.h\n",
            "[  4%] Built target neigh_list.h\n",
            "[  4%] Built target pair.h\n",
            "[  4%] Built target pointers.h\n",
            "[  5%] Built target region.h\n",
            "[  5%] Built target timer.h\n",
            "[  5%] Built target universe.h\n",
            "[  6%] Built target variable.h\n",
            "[  6%] Built target update.h\n",
            "[  6%] Built target utils.h\n",
            "[  7%] Built target group.h\n",
            "[  7%] Built target improper.h\n",
            "[  7%] Built target input.h\n",
            "[  7%] Built target info.h\n",
            "[  7%] Built target kspace.h\n",
            "[  7%] Built target lattice.h\n",
            "[  7%] Built target lammps.h\n",
            "[  7%] Built target compute.h\n",
            "[  7%] Built target dihedral.h\n",
            "[  7%] Built target domain.h\n",
            "[  7%] Built target library.h\n",
            "[  7%] Built target error.h\n",
            "[  7%] Built target fix.h\n",
            "[ 98%] Built target lammps\n",
            "[100%] Built target lmp\n"
          ]
        }
      ],
      "source": [
        "# compile lammps\n",
        "# Switch the Colab C++ compiler to g++-9.\n",
        "# !apt update\n",
        "# !apt install -y cmake\n",
        "\n",
        "#!wget \"https://github.com/lammps/lammps/archive/stable.zip\"\n",
        "!wget \"https://github.com/lammps/lammps/archive/refs/tags/patch_17Feb2022.zip\"\n",
        "!unzip -q patch_17Feb2022.zip\n",
        "!rm patch_17Feb2022.zip\n",
        "!mv lammps-patch_17Feb2022 lammps\n",
        "!cd flare/lammps_plugins && ./install.sh ../../lammps\n",
        "!cd lammps && mkdir -p build && cd build && cmake ../cmake -DPKG_MACHDYN=yes -DDOWNLOAD_EIGEN3=yes -DPKG_MANYBODY=yes && make -j4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71nC199wcBYS"
      },
      "source": [
        "# Bayesian active learning with FLARE and LAMMPS MD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbgVCAAdTlLY"
      },
      "source": [
        "## Step 1: Make the initial structure.\n",
        "\n",
        "We'll simulate an adatom on an aluminum slab to illustrate what happens when one local environment doesn't resemble any of the others in the structure.\n",
        "\n",
        "We need a file that stores the initial atomic structure for the on-the-fly training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hlzfUR2XX06j",
        "outputId": "7c029d0e-2e96-48b8-d9fb-adfb019e651a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c1a195d22bcf>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ASE imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAtoms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupercells\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ase'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import numpy and matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rc('font', size=12)\n",
        "matplotlib.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# ASE imports\n",
        "from ase import Atoms, units\n",
        "from ase.build import supercells\n",
        "from ase.visualize import view\n",
        "from ase.build import fcc111, add_adsorbate\n",
        "from ase.io import read, write\n",
        "\n",
        "# Create a slab with an adatom.\n",
        "atoms = fcc111(\"Al\", (4, 4, 6), vacuum=10.0)\n",
        "add_adsorbate(atoms, \"Al\", 2.5, \"ontop\")\n",
        "n_atoms = len(atoms)\n",
        "\n",
        "write(\"Al.xyz\", atoms)\n",
        "\n",
        "view(atoms, viewer='x3d')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr6V6gk_EG7n"
      },
      "source": [
        "## Step 2: Prepare a yaml configuration file\n",
        "\n",
        "The yaml config file is the input to FLARE to run on-the-fly/offline training. It includes four sections:\n",
        "1. `supercell`: the file of the initial structure is given. Any format supported by ASE IO can be used.\n",
        "2. `flare_calc`: set up the sparse GP parameters\n",
        "3. `dft_calc`: set up the DFT calculator. Any calculator supported by ASE can be used.\n",
        "4. `otf`: set up the on-the-fly training parameters, including MD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H5kcouMIdR35"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/mir-group/FLARE-Tutorials.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "czH5gZTdcNtT"
      },
      "outputs": [],
      "source": [
        "!cp lammps/potentials/Al_zhou.eam.alloy ./\n",
        "!cp FLARE-Tutorials/OTF/*.yaml .\n",
        "!cat lammps.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjnoC88QKKrx"
      },
      "source": [
        "The flexibility of LAMMPS allows us to use different `fix` commands, and grouping atoms using `region` and `group`. Here is an example\n",
        "```yaml\n",
        "    md_kwargs:\n",
        "        command: \"lammps/build/lmp\"\n",
        "        specorder: [Al]\n",
        "        dump_period: 10\n",
        "        pair_style: flare\n",
        "        region:\n",
        "            - \"bottom block INF INF INF INF INF 4.0\\n\"\n",
        "        group:\n",
        "            - \"frozen region bottom\"\n",
        "            - \"mobile subtract all frozen\"\n",
        "        fix:\n",
        "            - \"1 mobile nvt temp 2500 2500 $(100.0*dt)\"\n",
        "            - \"2 frozen setforce 0 0 0\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkUjVBJyFEJN"
      },
      "source": [
        "## Step 3: Run on-the-fly training\n",
        "\n",
        "If you want to use OpenMP parallelization to speed up FLARE, then set\n",
        "```\n",
        "export OMP_NUM_THREADS=<number_of_cpus_on_a_single_node>\n",
        "```\n",
        "\n",
        "To launch the training, in the command line, run `flare-otf <name>.yaml`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hOssRM0ut60Z"
      },
      "outputs": [],
      "source": [
        "!flare-otf lammps.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtX2TENaFyAr"
      },
      "source": [
        "## Step 4: Output files\n",
        "In the same folder as you run `flare-otf`, there will be multiple output files dumped during the training.\n",
        "\n",
        "| File name | Description |\n",
        "| --------- | ----------- |\n",
        "|`<output_name>.out` | log file of the OTF training |\n",
        "|`<output_name>_dft.xyz` | all the DFT computed frames and the corresponding DFT energy/forces/stress |\n",
        "|  `<output_name>_md.xyz` | complete MD trajectory from the on-the-fly training |\n",
        "| `<output_name>_dft.pickle`| ASE DFT calculator (used for restarting OTF) |\n",
        "| `<output_name>_flare.json`| FLARE calculator with training data collected from OTF (used for restarting) |\n",
        "| `<output_name>_thermo.txt`| thermal outputs from LAMMPS of the complete MD trajectory |\n",
        "| `<output_name>_atoms.json`| atomic structure at the current step (ASE Atoms object) |\n",
        "| `<output_name>_checkpt.json`| checkpoint file that saved the OTF information at the current step, and can be used to restart an OTF training |\n",
        "| `lmp.flare`| LAMMPS potential file generated by FLARE, and used for MD |\n",
        "| `L_inv_lmp.flare`, `sparse_desc_lmp.flare`| coefficient files used in LAMMPS for uncertainty predictions |\n",
        "| `<output_name>_ckpt_<n>` | (optional) If you set `write_model: 4`,  those folders back up the checkpoint files at step n |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIxm2Jb3W54D"
      },
      "source": [
        "## Step 5: Postprocessing\n",
        "\n",
        "In `myotf_thermo.txt`, the columns are\n",
        "step, temp, ke, pe, etotal, pxx, pyy, pzz, pyz, pxz, pxy, c_MaxUnc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S1TZIVbneP7E"
      },
      "outputs": [],
      "source": [
        "otf_data = np.loadtxt(\"myotf_thermo.txt\")\n",
        "steps = otf_data[:, 0] # 1 fs/step\n",
        "max_uncertainty = otf_data[:, -1]\n",
        "threshold = 0.02\n",
        "\n",
        "# Plot maximal atomic uncertainty at each MD step\n",
        "plt.plot(steps, max_uncertainty, color=\"blue\")\n",
        "\n",
        "# Plot the uncertainty threshold of calling DFT\n",
        "plt.plot(steps, threshold * np.ones_like(steps), \"--\", color=\"red\", label=\"Threshold\")\n",
        "\n",
        "# Plot DFT calls with grey dash lines\n",
        "steps_above_threshold = steps[max_uncertainty > threshold]\n",
        "for dft_step in steps_above_threshold:\n",
        "    if dft_step == steps_above_threshold[0]:\n",
        "        label = \"DFT\"\n",
        "    else:\n",
        "        label = None\n",
        "    plt.axvline(dft_step, linestyle=\":\", color=\"grey\", label=label)\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"Simulation time (fs)\")\n",
        "plt.ylabel(\"Maximal uncertainty\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eXUXUTZ3f8od"
      },
      "outputs": [],
      "source": [
        "temperatures = otf_data[:, 1]\n",
        "plt.plot(steps, temperatures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MRAuxsXNg2_e"
      },
      "outputs": [],
      "source": [
        "potential_energies = otf_data[:, 3]\n",
        "plt.plot(steps, potential_energies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ME7HiSPyaN"
      },
      "source": [
        "# Run MD in LAMMPS with uncertainty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYJVQ7XSWUEq"
      },
      "source": [
        "## Coefficient files for LAMMPS\n",
        "\n",
        "After the training is done, you will probably want to deploy the force field to large-scale molecular dynamics in LAMMPS. You need the coefficient files for FLARE pair styles (and compute commands if the uncertainty is needed to be calculated).\n",
        "\n",
        "The following files are needed for running FLARE in LAMMPS:\n",
        "\n",
        "- **Force field**: coefficient file `lmp.flare` for pair_flare energy/forces/stress. Can be a different file name. Used as\n",
        "\n",
        "  ```\n",
        "  pair_style\tflare\n",
        "  pair_coeff\t* * lmp.flare\n",
        "  ```\n",
        "\n",
        "- **(Optional) SGP uncertainty**: coefficient files `sparse_desc_lmp.flare` and `L_inv_lmp.flare` for sparse GP uncertainty calculation. Can be different file names. Used as\n",
        "\n",
        "  ```\n",
        "  compute unc all flare/std/atom L_inv_lmp.flare sparse_desc_lmp.flare\n",
        "  ```\n",
        "\n",
        "  Note: this is the exact SGP uncertainty, and its computational cost grows quadratically with the sparse set size.\n",
        "\n",
        "- **(Optional) Mapped uncertainty**: coefficient file  `mapped_unc_lmp.flare` for mapped uncertainty calculation. Can be a different file name. Used as\n",
        "\n",
        "  ```\n",
        "  compute unc all flare/std/atom map_unc_lmp.flare\n",
        "  ```\n",
        "\n",
        "  Note:\n",
        "  1. This is the mapped uncertainty which is an approximation of the exact SGP uncertainty with a much cheaper computational cost comparable to the force field. See details in [this paper](https://arxiv.org/abs/2203.03824).\n",
        "  2. Basically, when there are two coefficient files after `compute unc all flare/std/atom` it will calculate the exact SGP uncertainty, when there is one coefficient file it will calculate the mapped uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Hb_XTtbUUF"
      },
      "source": [
        "## Generate coefficient files\n",
        "\n",
        "- If you have set `use_mapping: True` in the on-the-fly/offline training, then at the end of the training you will have `lmp.flare`, `sparse_desc_lmp.flare` and `L_inv_lmp.flare` available in the current directory.\n",
        "\n",
        "- If you do not have the coefficient files, you will need the json file of the sparse GP calculator which can be found in the same folder as the training. In the above example, it is `Al_flare.json`. Then run the simple script below. You can put your name as the contributor, and then `lmp.flare`, `sparse_desc_lmp.flare` and `L_inv_lmp.flare` will be generated in the current directory.\n",
        "\n",
        "> **NOTE**: This script is useful for constructing potential files. You should keep it and can use it after restarting an active learning trajectory, offline training, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Px4Z7QHxWVT7"
      },
      "outputs": [],
      "source": [
        "from flare.bffs.sgp.calculator import SGP_Calculator\n",
        "\n",
        "sgp_calc, _ = SGP_Calculator.from_file(\"myotf_flare.json\")\n",
        "sgp_calc.build_map(\"lmp.flare\", \"your_name\", map_uncertainty=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrCzESVmQYDj"
      },
      "source": [
        "If `map_uncertainty=True`, the mapped uncertainty coefficient file `map_unc_lmp.flare` will be generated instead of `sparse_desc_lmp.flare` and `L_inv_lmp.flare`. It might take a while because a new SGP with `power=1` kernel will be constructed and mapped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlr0Hesc88x"
      },
      "source": [
        "## Run MD with uncertainty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN-ViBCTdSIq"
      },
      "source": [
        "Prepare a LAMMPS data file\n",
        "\n",
        "\n",
        "> **Note**: if you are using ASE to write a LAMMPS data file, be careful of the species order. Make sure you set up the `specorder` to the list of the elements with the same order specified in the yaml file of the on-the-fly training. Otherwise, ASE will assign type ID to atoms based on the order of their chemical numbers by default. The inconsistency between the atomic type ID and the potential type order will make the energy/forces/stress prediction wrong.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WqBW2lghdUyo"
      },
      "outputs": [],
      "source": [
        "! mkdir lammps_run\n",
        "\n",
        "from ase.io import read, write\n",
        "atoms = read(\"Al.xyz\")\n",
        "write(\"lammps_run/Al.data\", atoms, format=\"lammps-data\", specorder=[\"Al\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZGTqL9Tdp_k"
      },
      "source": [
        "Copy LAMMPS coefficient files for FLARE potential and uncertainty to the directory of MD run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EWfD6dvaduxw"
      },
      "outputs": [],
      "source": [
        "!cp lmp.flare L_inv_lmp.flare sparse_desc_lmp.flare lammps_run/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YzlpUvbdZBf"
      },
      "source": [
        "Prepare a LAMMPS input file. Here we set up an NVT run at 300K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fdeo7HvCgss3"
      },
      "outputs": [],
      "source": [
        "!cp FLARE-Tutorials/OTF/lammps.in lammps_run/\n",
        "!cat lammps_run/lammps.in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgyBdpvzd2bk"
      },
      "source": [
        "Run LAMMPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rwYIXLQRwah0"
      },
      "outputs": [],
      "source": [
        "!cd lammps_run && ../lammps/build/lmp -in lammps.in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH2-qLxsaN89"
      },
      "source": [
        "Using Python to call LAMMPS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr6Clc1VDTo0"
      },
      "source": [
        "## Visualize LAMMPS MD trajectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-cYF_Anc5M8"
      },
      "source": [
        "### Color Atoms by Uncertainty\n",
        "\n",
        "If you just run the on-the-fly training with PyLAMMPS or you used this\n",
        "```\n",
        "compute unc all flare/std/atom L_inv_lmp.flare sparse_desc_lmp.flare\n",
        "compute MaxUnc all reduce max c_unc\n",
        "\n",
        "dump dump_all all custom 10 output.dump id type x y z fx fy fz c_unc\n",
        "thermo_style custom step temp pe etotal press vol c_MaxUnc\n",
        "```\n",
        "in your LAMMPS MD input script, then the uncertainty information is dumped. In the dumped trajectory, the atomic uncertainty is recorded in the last column `c_unc`. In the thermostat file (LAMMPS `log` file), the maximal atomic uncertainty in each step is recorded in the last column `c_MaxUnc`.\n",
        "\n",
        "You can visualize the dumped trajectory `output.dump` in softwares like [OVITO](https://www.ovito.org), where the atomic uncertainty `c_unc` can be used for `color coding`.\n",
        "\n",
        "<img src=\"https://github.com/mir-group/FLARE-Tutorials/raw/master/APS-2020/al.gif\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwTC3g3hDOxH"
      },
      "source": [
        "### Plot Thermostat\n",
        "\n",
        "Here we plot the temperature and maximal atomic uncertainty with the simulation time. The data is extracted from the LAMMPS log file, using a python package `lammps-logfile`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cEFYf20HweCQ"
      },
      "outputs": [],
      "source": [
        "!pip install lammps-logfile\n",
        "\n",
        "import lammps_logfile\n",
        "\n",
        "log = lammps_logfile.File(\"lammps_run/log.lammps\")\n",
        "plt.plot(log.get(\"Step\"), log.get(\"Temp\"))\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Temperature (K)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmKGSu73R72u"
      },
      "source": [
        "The maximal atomic uncertainty can be used to monitor how confident the model is, and how far the current step gets away from the training data. It is very helpful for monitoring if unphysical behavior happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CalqPVYHo3NS"
      },
      "outputs": [],
      "source": [
        "plt.plot(log.get(\"Step\"), log.get(\"c_MaxUnc\"))\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Max uncertainty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TlT3X7mmhkeF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}